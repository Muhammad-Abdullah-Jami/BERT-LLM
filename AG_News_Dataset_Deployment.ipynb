{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muhammad-Abdullah-Jami/BERT-LLM/blob/main/AG_News_Dataset_Deployment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8638c795",
      "metadata": {
        "id": "8638c795"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers[torch] --upgrade\n",
        "# !pip install accelerate --upgrade\n",
        "# !pip install datasets\n",
        "# !pip install datasets pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd738732",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd738732",
        "outputId": "a3961508-b98a-42d7-c27f-dbaf6355004f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Aug 11 06:25:01 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe377201",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe377201",
        "outputId": "656bd3f5-0b93-439d-d306-a185c6f2a179"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4850' max='19140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 4850/19140 10:21 < 30:32, 7.80 it/s, Epoch 0.76/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load the AG News dataset\n",
        "dataset = load_dataset(\"ag_news\")\n",
        "\n",
        "# Convert the dataset to DataFrames\n",
        "df_train = pd.DataFrame(dataset['train'])\n",
        "df_test = pd.DataFrame(dataset['test'])\n",
        "df = pd.concat([df_train, df_test])\n",
        "\n",
        "# Define label mapping\n",
        "label_mapping = {0: 'World', 1: 'Sports', 2: 'Business', 3: 'Sci/Tech'}\n",
        "df['label'] = df['label'].map(label_mapping)\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenizing the text data\n",
        "def tokenize_data(df, tokenizer):\n",
        "    return tokenizer(\n",
        "        df['text'].tolist(),\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "# Tokenize the training and validation data\n",
        "train_encodings = tokenize_data(train_df, tokenizer)\n",
        "val_encodings = tokenize_data(val_df, tokenizer)\n",
        "\n",
        "# Encode labels to tensor format\n",
        "def encode_labels(df, label_mapping):\n",
        "    return torch.tensor(df['label'].map({v: k for k, v in label_mapping.items()}).values)\n",
        "\n",
        "train_labels = encode_labels(train_df, label_mapping)\n",
        "val_labels = encode_labels(val_df, label_mapping)\n",
        "\n",
        "# Create a custom Dataset class\n",
        "class AGNewsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: tensor[idx] for key, tensor in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Create the PyTorch datasets\n",
        "train_dataset = AGNewsDataset(train_encodings, train_labels)\n",
        "val_dataset = AGNewsDataset(val_encodings, val_labels)\n",
        "\n",
        "# Load the BERT model for sequence classification\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_mapping))\n",
        "\n",
        "# Move model to the device\n",
        "model.to(device)\n",
        "\n",
        "# Define the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',  # Directory for storing logs\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",  # Run evaluation at the end of each epoch\n",
        "    fp16=True,  # Set to False for CPU usage\n",
        "    save_strategy=\"epoch\",  # Save checkpoints at each epoch\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "# Define the metrics function\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1 = f1_score(labels, preds, average='weighted')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {'f1': f1, 'accuracy': acc}\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the trained model\n",
        "trainer.save_model('./ag_news_model')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ROrw8P89IKCk",
      "metadata": {
        "id": "ROrw8P89IKCk"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_loss, label='Training Loss')\n",
        "plt.plot(eval_loss, label='Validation Loss')\n",
        "plt.xlabel('Steps/Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot validation accuracy\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(eval_accuracy, label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot validation F1 score\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(eval_f1, label='Validation F1 Score')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4ad79f7",
      "metadata": {
        "id": "e4ad79f7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path in Google Drive where you want to save the model\n",
        "drive_model_path = '/content/drive/MyDrive/ag_news_model'\n",
        "\n",
        "# Create directory in Google Drive if it does not exist\n",
        "os.makedirs(drive_model_path, exist_ok=True)\n",
        "\n",
        "# Define the local path of the saved model\n",
        "local_model_path = './ag_news_model'\n",
        "\n",
        "# Move the saved model to Google Drive\n",
        "shutil.copytree(local_model_path, drive_model_path, dirs_exist_ok=True)\n",
        "\n",
        "print(f\"Model has been moved to Google Drive at {drive_model_path}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91883b4f",
      "metadata": {
        "id": "91883b4f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d2806ad",
      "metadata": {
        "id": "6d2806ad"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b82ea4c",
      "metadata": {
        "id": "6b82ea4c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b8b7db3",
      "metadata": {
        "id": "0b8b7db3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0d9a478",
      "metadata": {
        "id": "b0d9a478"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}